<?xml version="1.0" encoding="utf-8" ?><rss version="2.0" xml:base="http://vgtc.org/taxonomy/term/544/all" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:foaf="http://xmlns.com/foaf/0.1/" xmlns:og="http://ogp.me/ns#" xmlns:rdfs="http://www.w3.org/2000/01/rdf-schema#" xmlns:sioc="http://rdfs.org/sioc/ns#" xmlns:sioct="http://rdfs.org/sioc/types#" xmlns:skos="http://www.w3.org/2004/02/skos/core#" xmlns:xsd="http://www.w3.org/2001/XMLSchema#">
  <channel>
    <title>DC</title>
    <link>http://vgtc.org/taxonomy/term/544/all</link>
    <description></description>
    <language>en</language>
          <item>
    <title>Video See Through AR Head-Mounted Display for Medical Procedures</title>
    <link>http://vgtc.org/archives/ismar/2014/st/video-see-through-ar-head-mounted-display-medical-procedures</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt; Fabrizio Cutolo, Paolo Domenico Parchi, Vincenzo Ferrari&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;In the context of image-guided surgery (IGS), AR technology appears as a significant development in the field since it complements and integrates the concepts of surgical navigation based on virtual reality. The aim of the project is to optimize and validate an ergonomic, accurate and cheap video see-through AR system as an aid in various typologies of surgical procedures. The system will ideally have to be inexpensive and user-friendly to be successfully introduced in the clinical practice.&lt;/p&gt;
&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/ismar.2014.6948504&quot;&gt;http://dx.doi.org/10.1109/ismar.2014.6948504&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/ismar/2014/st/dc&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;DC&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-keywords field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Keywords:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Image-guided surgery, Interest point and salient region detections, Medical device validation, Mixed / augmented reality, Object detection, Tracking&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;1&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Wed, 22 Apr 2015 09:00:22 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">978 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Corneal Imaging in Localization and HMD interaction</title>
    <link>http://vgtc.org/archives/ismar/2014/st/corneal-imaging-localization-and-hmd-interaction</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt; Alexander Plopski, Kiyoshi Kiyokawa, Haruo Takemura, Christian Nitschke&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;The human eyes perceive our surroundings and are one of, if not our most important sensory organs. Contrary to our other senses the eyes not only perceive but also provide information to a keen observer. However, thus far this has been mainly used to detect reflection of infrared light sources to estimate the user&#039;s gaze. The reflection of the visible spectrum on the other hand has rarely been utilized.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/ismar.2014.6948505&quot;&gt;http://dx.doi.org/10.1109/ismar.2014.6948505&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/ismar/2014/st/dc&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;DC&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-keywords field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Keywords:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Augmented reality, Corneal imaging, Optical see-through head mounted display&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;2&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Wed, 22 Apr 2015 09:00:22 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">979 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Semantic Contextual Augmented Reality Environments </title>
    <link>http://vgtc.org/archives/ismar/2014/st/semantic-contextual-augmented-reality-environments</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Dariusz Ruminski, Krzysztof Walczak&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;The paper presents the concept of dynamic Contextual Augmented Reality Environments (CARE), in which augmentation presented to users is dynamically constructed based on four semantically described elements. The first element is the user&#039;s context (preferences, privileges, location, time, device&#039;s capabilities). The second element is a set of trackables — visual markers representing real world objects that can be augmented for a given user in a given context.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/ismar.2014.6948506&quot;&gt;http://dx.doi.org/10.1109/ismar.2014.6948506&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/ismar/2014/st/dc&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;DC&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;3&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Wed, 22 Apr 2015 09:00:22 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">980 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Designing Support for Collaboration around Physical Artefacts: Using Augmented Reality in Learning Environments </title>
    <link>http://vgtc.org/archives/ismar/2014/st/designing-support-collaboration-around-physical-artefacts-using-augmented</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Jason Weigel, Stephen Viller, Mark Schulz&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;The aim of this thesis is to identify mechanisms for supporting collaboration around physical artefacts in co-located and remote settings. To explore the research question in the project, a Research through Design approach has been adopted. A technology probe — an evolutionary prototype of a remote collaboration system — will be used to fuel the research. The prototype will facilitate collaboration between small groups around physical artefacts in an augmented learning environment. The prototype will inform future collaborative augmented reality technology design.&lt;/p&gt;
&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/ismar.2014.6948507&quot;&gt;http://dx.doi.org/10.1109/ismar.2014.6948507&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/ismar/2014/st/dc&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;DC&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-keywords field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Keywords:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Collaboration, Augmented reality, Remote learning&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;4&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Wed, 22 Apr 2015 09:00:22 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">981 at http://vgtc.org</guid>
  </item>
  </channel>
</rss>
