<?xml version="1.0" encoding="utf-8" ?><rss version="2.0" xml:base="http://vgtc.org/taxonomy/term/554/all" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:foaf="http://xmlns.com/foaf/0.1/" xmlns:og="http://ogp.me/ns#" xmlns:rdfs="http://www.w3.org/2000/01/rdf-schema#" xmlns:sioc="http://rdfs.org/sioc/ns#" xmlns:sioct="http://rdfs.org/sioc/types#" xmlns:skos="http://www.w3.org/2004/02/skos/core#" xmlns:xsd="http://www.w3.org/2001/XMLSchema#">
  <channel>
    <title>Long Paper</title>
    <link>http://vgtc.org/taxonomy/term/554/all</link>
    <description></description>
    <language>en</language>
          <item>
    <title>Source and Listener Directivity for Interactive Wave-based Sound Propagation</title>
    <link>http://vgtc.org/archives/vr/2014/source-and-listener-directivity-interactive-wave-based-sound-propagation</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Ravish Mehra, Lakulish Antani, Sujeong Kim, Dinesh Manocha&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;We present an approach to model dynamic, data-driven source and listener directivity for interactive wave-based sound propagation in virtual environments and computer games. Our directional source representation is expressed as a linear combination of elementary spherical harmonic (SH) sources. In the preprocessing stage, we precompute and encode the propagated sound fields due to each SH source.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/TVCG.2014.38&quot;&gt;http://dx.doi.org/10.1109/TVCG.2014.38&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/vr/2014/long-paper&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;Long Paper&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;3&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Thu, 23 Apr 2015 03:44:26 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">1130 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Exchange of Avatars: Toward a Better Perception and Understanding</title>
    <link>http://vgtc.org/archives/vr/2014/exchange-avatars-toward-better-perception-and-understanding</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Thomas Lopez, Rozenn Bouville, Emilie Loup-escande, Florian Nouviale, Valerie Gouranton, Bruno Arnaldi&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;The exchange of avatars, i.e. the actual fact of changing once avatar with another one, is a promising trend in multi-actor virtual environments. It provides new opportunities for users, such as controlling a different avatar for a specific action, retrieving knowledge belonging to a particular avatar, solving conflicts and deadlocks situations or even helping another user. Virtual Environments for Training are especially affected by this trend as a specific role derived from a scenario is usually assigned to a unique avatar.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/TVCG.2014.22&quot;&gt;http://dx.doi.org/10.1109/TVCG.2014.22&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/vr/2014/long-paper&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;Long Paper&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;19&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Thu, 23 Apr 2015 03:44:26 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">1146 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Getting the Point Across: Exploring the Effects of Dynamic Virtual Humans in an Interactive Museum Exhibit on User Perceptions</title>
    <link>http://vgtc.org/archives/vr/2014/getting-point-across-exploring-effects-dynamic-virtual-humans-interactive-museum</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Diego Rivera-Gutierrez, Rick Ferdig, Jian Li, Benjamin Lok&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;We have created “You, M.D.”, an interactive museum exhibit in which users learn about topics in public health literacy while interacting with virtual humans. You, M.D. is equipped with a weight sensor, a height sensor and a Microsoft Kinect that gather basic user information. Conceptually, You, M.D. could use this user information to dynamically select the appearance of the virtual humans in the interaction attempting to improve learning outcomes and user perception for each particular user.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/TVCG.2014.26&quot;&gt;http://dx.doi.org/10.1109/TVCG.2014.26&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/vr/2014/long-paper&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;Long Paper&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;18&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Thu, 23 Apr 2015 03:44:26 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">1145 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Effects of Virtual Human Animation on Emotion Contagion in Simulated Inter-Personal Experiences</title>
    <link>http://vgtc.org/archives/vr/2014/effects-virtual-human-animation-emotion-contagion-simulated-inter-personal</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Yanxiang Wu, Sabarish V. Babu, Rowan Armstrong, Jeffrey W. Bertrand, Jun Luo, Tania Roy, Shaundra B. Daily, Lauren Cairco Dukes, Larry F. Hodges, Tracy Fasolino&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;We empirically examined the impact of virtual human animation on the emotional responses of participants in a medical virtual reality system for education in the signs and symptoms of patient deterioration. Participants were presented with one of two virtual human conditions in a between-subjects experiment, static (non-animated) and dynamic (animated).&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/TVCG.2014.19&quot;&gt;http://dx.doi.org/10.1109/TVCG.2014.19&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/vr/2014/long-paper&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;Long Paper&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;17&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Thu, 23 Apr 2015 03:44:26 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">1144 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Measuring Latency in Virtual Environments </title>
    <link>http://vgtc.org/archives/vr/2014/measuring-latency-virtual-environments</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Sebastian Friston, Anthony Steed&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Latency of interactive computer systems is a product of the processing, transport and synchronisation delays inherent to the components that create them. In a virtual environment (VE) system, latency is known to be detrimental to a user&#039;s sense of immersion, physical performance and comfort level. Accurately measuring the latency of a VE system for study or optimisation, is not straightforward. A number of authors have developed techniques for characterising latency, which have become progressively more accessible and easier to use. In this paper, we characterise these techniques.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/TVCG.2014.30&quot;&gt;http://dx.doi.org/10.1109/TVCG.2014.30&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/vr/2014/long-paper&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;Long Paper&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;16&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Thu, 23 Apr 2015 03:44:26 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">1143 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Feasibility of Training Athletes for High-Pressure Situations Using Virtual Reality</title>
    <link>http://vgtc.org/archives/vr/2014/feasibility-training-athletes-high-pressure-situations-using-virtual-reality</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Cheryl Stinson, Doug A. Bowman&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Virtual reality (VR) has been successfully applied to a broad range of training domains; however, to date there is little research investigating its benefits for sport psychology training. We hypothesized that using high-fidelity VR systems to display realistic 3D sport environments could trigger anxiety, allowing resilience-training systems to prepare athletes for real-world, high-pressure situations. In this work we investigated the feasibility and usefulness of using VR for sport psychology training.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/TVCG.2014.23&quot;&gt;http://dx.doi.org/10.1109/TVCG.2014.23&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/vr/2014/long-paper&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;Long Paper&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;15&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Thu, 23 Apr 2015 03:44:26 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">1142 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Dynamic Affordances in Embodied Interactive Systems: The Role of Display and Mode of Locomotion</title>
    <link>http://vgtc.org/archives/vr/2014/dynamic-affordances-embodied-interactive-systems-role-display-and-mode-locomotion</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Timofey Y. Grechkin, Jodie M. Plumert, Joseph K. Kearney&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;We investigated how the properties of interactive virtual reality systems affect user behavior in full-body embodied interactions. Our experiment compared four interactive virtual reality systems using different display types (CAVE vs. HMD) and modes of locomotion (walking vs. joystick). Participants performed a perceptual-motor coordination task, in which they had to choose among a series of opportunities to pass through a gate that cycled open and closed and then board a moving train. Mode of locomotion, but not type of display, affected how participants chose opportunities for action.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/TVCG.2014.18&quot;&gt;http://dx.doi.org/10.1109/TVCG.2014.18&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/vr/2014/long-paper&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;Long Paper&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;14&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Thu, 23 Apr 2015 03:44:26 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">1141 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Recalibration of Perceived Distance in Virtual Environments Occurs Rapidly and Transfers Asymmetrically Across Scale</title>
    <link>http://vgtc.org/archives/vr/2014/recalibration-perceived-distance-virtual-environments-occurs-rapidly-and-transfers</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Jonathan W. Kelly, William W. Hammel, Zachary D. Siegel, Lori A. Sjolund&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Distance in immersive virtual reality is commonly underperceived relative to intended distance, causing virtual environments to appear smaller than they actually are. However, a brief period of interaction by walking through the virtual environment with visual feedback can cause dramatic improvement in perceived distance.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/TVCG.2014.36&quot;&gt;http://dx.doi.org/10.1109/TVCG.2014.36&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/vr/2014/long-paper&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;Long Paper&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;13&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Thu, 23 Apr 2015 03:44:26 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">1140 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Performance of Redirected Walking Algorithms in a Constrained Virtual World</title>
    <link>http://vgtc.org/archives/vr/2014/performance-redirected-walking-algorithms-constrained-virtual-world</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Eric Hodgson, Eric Bachmann, Tyler Thrash&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Redirected walking algorithms imperceptibly rotate a virtual scene about users of immersive virtual environment systems in order to guide them away from tracking area boundaries. Ideally, these distortions permit users to explore large unbounded virtual worlds while walking naturally within a physically limited space. Many potential virtual worlds are composed of corridors, passageways, or aisles.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/TVCG.2014.34&quot;&gt;http://dx.doi.org/10.1109/TVCG.2014.34&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/vr/2014/long-paper&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;Long Paper&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;12&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Thu, 23 Apr 2015 03:44:26 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">1139 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Establishing the Range of Perceptually Natural Visual Walking Speeds for Virtual Walking-In-Place Locomotion</title>
    <link>http://vgtc.org/archives/vr/2014/establishing-range-perceptually-natural-visual-walking-speeds-virtual-walking-place</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Niels Christian Nilsson, Stefania Serafin, Rolf Nordahl&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Walking-In-Place (WIP) techniques make it possible to facilitate relatively natural locomotion within immersive virtual environments that are larger than the physical interaction space. However, in order to facilitate natural walking experiences one needs to know how to map steps in place to virtual motion. This paper describes two within-subjects studies performed with the intention of establishing the range of perceptually natural walking speeds for WIP locomotion.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/TVCG.2014.21&quot;&gt;http://dx.doi.org/10.1109/TVCG.2014.21&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/vr/2014/long-paper&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;Long Paper&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;11&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Thu, 23 Apr 2015 03:44:26 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">1138 at http://vgtc.org</guid>
  </item>
  <item>
    <title>FlyAR: Augmented Reality Supported Micro Aerial Vehicle Navigation</title>
    <link>http://vgtc.org/archives/vr/2014/flyar-augmented-reality-supported-micro-aerial-vehicle-navigation</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Stefanie Zollmann, Christof Hoppe, Tobias Langlotz, Gerhard Reitmayr&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Micro aerial vehicles equipped with high-resolution cameras can be used to create aerial reconstructions of an area of interest. In that context automatic flight path planning and autonomous flying is often applied but so far cannot fully replace the human in the loop, supervising the flight on-site to assure that there are no collisions with obstacles.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/TVCG.2014.24&quot;&gt;http://dx.doi.org/10.1109/TVCG.2014.24&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/vr/2014/long-paper&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;Long Paper&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;10&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Thu, 23 Apr 2015 03:44:26 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">1137 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Real-time Human Pose and Shape Estimation for Virtual Try-On Using a Single Commodity Depth Camera</title>
    <link>http://vgtc.org/archives/vr/2014/real-time-human-pose-and-shape-estimation-virtual-try-using-single-commodity-depth</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Mao Ye, Huamin Wang, Nianchen Deng, Xubo Yang, Ruigang Yang&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;We present a system that allows the user to virtually try on new clothes. It uses a single commodity depth camera to capture the user in 3D. Both the pose and the shape of the user are estimated with a novel real-time template-based approach that performs tracking and shape adaptation jointly. The result is then used to drive realistic cloth simulation, in which the synthesized clothes are overlayed on the input image. The main challenge is to handle missing data and pose ambiguities due to the monocular setup, which captures less than 50 percent of the full body.&lt;/p&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/vr/2014/long-paper&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;Long Paper&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;9&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Thu, 23 Apr 2015 03:44:26 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">1136 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Geometrically-correct projection-based texture mapping onto a deformable object</title>
    <link>http://vgtc.org/archives/vr/2014/geometrically-correct-projection-based-texture-mapping-deformable-object</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Yuichiro Fujimoto, Ross Smith, Takafumi Taketomi, Goshiro Yamamoto, Jun Miyazaki, Hirokazu Kato, Bruce Thomas&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Projection-based Augmented Reality commonly employs a rigid substrate as the projection surface and does not support scenarios where the substrate can be reshaped. This investigation presents a projection-based AR system that supports deformable substrates that can be bent, twisted or folded. We demonstrate a new invisible marker embedded into a deformable substrate and an algorithm that identifies deformations to project geometrically correct textures onto the deformable object.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/TVCG.2014.25&quot;&gt;http://dx.doi.org/10.1109/TVCG.2014.25&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/vr/2014/long-paper&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;Long Paper&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;8&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Thu, 23 Apr 2015 03:44:26 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">1135 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Global Localization from Monocular SLAM on a Mobile Phone</title>
    <link>http://vgtc.org/archives/vr/2014/global-localization-monocular-slam-mobile-phone</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Jonathan Ventura, Clemens Arth, Gerhard Reitmayr, Dieter Schmalstieg&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;We propose the combination of a keyframe-based monocular SLAM system and a global localization method. The SLAM system runs locally on a camera-equipped mobile client and provides continuous, relative 6DoF pose estimation as well as keyframe images with computed camera locations. As the local map expands, a server process localizes the keyframes with a pre-made, globally-registered map and returns the global registration correction to the mobile client.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/TVCG.2014.27&quot;&gt;http://dx.doi.org/10.1109/TVCG.2014.27&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/vr/2014/long-paper&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;Long Paper&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;7&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Thu, 23 Apr 2015 03:44:26 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">1134 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Mixed Reality Virtual Pets to Reduce Childhood Obesity</title>
    <link>http://vgtc.org/archives/vr/2014/mixed-reality-virtual-pets-reduce-childhood-obesity</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Kyle Johnsen, Sun Joo Ahn, James Moore, Scott Brown, Thomas P. Robertson, Amanda Marable, Aryabrata Basu&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Novel approaches are needed to reduce the high rates of childhood obesity in the developed world. While multifactorial in cause, a major factor is an increasingly sedentary lifestyle of children. Our research shows that a mixed reality system that is of interest to children can be a powerful motivator of healthy activity. We designed and constructed a mixed reality system that allowed children to exercise, play with, and train a virtual pet using their own physical activity as input.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/TVCG.2014.33&quot;&gt;http://dx.doi.org/10.1109/TVCG.2014.33&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/vr/2014/long-paper&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;Long Paper&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;6&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Thu, 23 Apr 2015 03:44:26 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">1133 at http://vgtc.org</guid>
  </item>
  </channel>
</rss>
