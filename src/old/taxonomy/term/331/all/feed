<?xml version="1.0" encoding="utf-8" ?><rss version="2.0" xml:base="http://vgtc.org/taxonomy/term/331/all" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:foaf="http://xmlns.com/foaf/0.1/" xmlns:og="http://ogp.me/ns#" xmlns:rdfs="http://www.w3.org/2000/01/rdf-schema#" xmlns:sioc="http://rdfs.org/sioc/ns#" xmlns:sioct="http://rdfs.org/sioc/types#" xmlns:skos="http://www.w3.org/2004/02/skos/core#" xmlns:xsd="http://www.w3.org/2001/XMLSchema#">
  <channel>
    <title>posters</title>
    <link>http://vgtc.org/taxonomy/term/331/all</link>
    <description></description>
    <language>en</language>
          <item>
    <title>Poster: Interactive Breadboard Activity Simulation (IBAS) for Psychomotor Skills Education in Electrical Circuitry</title>
    <link>http://vgtc.org/archives/3dui/2014/poster-interactive-breadboard-activity-simulation-ibas-psychomotor-skills</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Dhaval Parmar, Jeffrey Bertrand, Blair Shannon, Sabarish V. Babu, Kapil Madathil, Melissa Zelaya, Tianwei Wang, John Wagner, Kristin Frady, Anand K. Gramopadhye&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;We present an interactive breadboard activity simulation (IBAS) to educate users in acquiring psychomotor skills in electrical circuitry pertaining to the ammeter, voltmeter and multimeter instruments. Psychomotor skills learning involves the association of cognitive functions with motor functions to make the task autonomous with repeated practice, and promoting better recall.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/3DUI.2014.6798880&quot;&gt;http://dx.doi.org/10.1109/3DUI.2014.6798880&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-video-download-url field-type-link-field field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Video:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://vimeo.com/groups/3dui2014/videos/90536918&quot;&gt;Download Video&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-running-time field-type-text field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Running Time:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;00:00:49&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/3dui/2014/posters&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;posters&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-keywords field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Keywords:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Education, 3D human-computer interaction&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;27&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Wed, 22 Apr 2015 08:15:07 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">483 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Poster: Investigating Viewpoint Visualizations for Click &amp; Go Navigation</title>
    <link>http://vgtc.org/archives/3dui/2014/poster-investigating-viewpoint-visualizations-click-go-navigation</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Benjamin Nuernberger, Steffen Gauglitz, Tobias Hollerer, Matthew Turk&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;We present an investigation of viewpoint visualizations for ﾴClick &amp;amp; Goﾡ 3D navigation interfaces based on a pre-populated set of viewpoints. These scenarios often occur in 3D navigation systems that are based on sets of photos and possibly an underlying 3D reconstruction. Given these photos (and the 3D reconstruction), how does one most effectively navigate through this environment? Existing systems often employ Click &amp;amp; Go interfaces which allow users to navigate with one click of the mouse or tap of the finger.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/3DUI.2014.6798869&quot;&gt;http://dx.doi.org/10.1109/3DUI.2014.6798869&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/3dui/2014/posters&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;posters&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;16&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Wed, 22 Apr 2015 08:15:07 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">472 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Poster: Immersive Point Cloud Virtual Environments</title>
    <link>http://vgtc.org/archives/3dui/2014/poster-immersive-point-cloud-virtual-environments</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Gerd Bruder, Frank Steinicke, Andreas Nuchter&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Today&#039;s three-dimensional (3D) virtual environments (VEs) are usually based on textured polygonal 3D models, which represent the appearance and geometry of the virtual world. However, some application domains require other graphical paradigms, which are currently not adequately addressed by 3D user interfaces. We introduce a novel approach for a technical human-robot telepresence setup that allows a human observer to explore a VE, which is a 3D reconstruction of the real world based on point clouds.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/3DUI.2014.6798870&quot;&gt;http://dx.doi.org/10.1109/3DUI.2014.6798870&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/3dui/2014/posters&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;posters&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;17&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Wed, 22 Apr 2015 08:15:07 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">473 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Poster: Rapid Development of Natural User Interaction using Kinect Sensors and VRPN</title>
    <link>http://vgtc.org/archives/3dui/2014/poster-rapid-development-natural-user-interaction-using-kinect-sensors-and-vrpn</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Timothy B. Morgan, Diana Jarrell, Judy M. Vance&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;The availability of low-cost natural user interaction (NUI) hardware took a significant step forward in 2010 with the introduction of the Microsoft Kinect. Despite significant work on the available software development kits for the Kinect, tasks beyond simple single-Kinect skeleton tracking remain challenging to implement. This paper introduces a software tool that significantly accelerates the prototyping and implementation of NUI in virtual reality, particularly for developers with limited programming skills.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/3DUI.2014.6798871&quot;&gt;http://dx.doi.org/10.1109/3DUI.2014.6798871&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/3dui/2014/posters&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;posters&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-keywords field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Keywords:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Natural user interaction, Microsoft Kinect, depth camera, virtual reality&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;18&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Wed, 22 Apr 2015 08:15:07 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">474 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Poster: Dynamic Adaptation of 3D Selection Techniques for Suitability Across Diverse Scenarios</title>
    <link>http://vgtc.org/archives/3dui/2014/poster-dynamic-adaptation-3d-selection-techniques-suitability-across-diverse</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Jeffrey Cashion, Joseph J. LaViola, Jr.&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;We performed a user study that measured the effectiveness of our new 3D selection technique, Scope, which dynamically adapts to the environment by altering its activation area and visual appearance with relation to cursor velocity. Users tested our new technique against existing techniques Raycast, Bendcast, and Hook across a variety of different 3D scenarios which featured three different levels of object density and three different levels of object velocity. Our two dependent variables were completion time and total attempts per scenario.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/3DUI.2014.6798872&quot;&gt;http://dx.doi.org/10.1109/3DUI.2014.6798872&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-video-download-url field-type-link-field field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Video:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://vimeo.com/groups/3dui2014/videos/90535902&quot;&gt;Download Video&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-running-time field-type-text field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Running Time:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;00:00:51&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/3dui/2014/posters&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;posters&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-keywords field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Keywords:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Interaction techniques, 3D object selection, dense and dynamic environments&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;19&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Wed, 22 Apr 2015 08:15:07 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">475 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Poster: Understanding of Spatial Gestural Motor Space: a Study on Cursorless Absolute Freehand Pointing on Large Displays</title>
    <link>http://vgtc.org/archives/3dui/2014/poster-understanding-spatial-gestural-motor-space-study-cursorless-absolute</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Seungjae Oh, Heejin Kim, Min K. Chung&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;As a preliminary research into extending the concept of direct touch to indirect spatial gesture, we conducted a user study to determine the relationship between gestural motor space and display space. From the results of a user study, we define a user-driven mapping between an area on motor space and a point on visual space. For 16 points in display space, we find the motor space radius interval of a standard deviation from mean and angle interval that statistically cover 96% of trials.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/3DUI.2014.6798873&quot;&gt;http://dx.doi.org/10.1109/3DUI.2014.6798873&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-video-download-url field-type-link-field field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Video:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://vimeo.com/groups/3dui2014/videos/90536095&quot;&gt;Download Video&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-running-time field-type-text field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Running Time:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;00:01:05&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/3dui/2014/posters&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;posters&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;20&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Wed, 22 Apr 2015 08:15:07 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">476 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Poster: Bimanual Design of Deformable Objects Thanks to the Multi-tool Visual Metaphor</title>
    <link>http://vgtc.org/archives/3dui/2014/poster-bimanual-design-deformable-objects-thanks-multi-tool-visual-metaphor</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Morgan Le Chenechal, Maud Marchal, Bruno Arnaldi&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;As a preliminary research into extending the concept of direct touch to indirect spatial gesture, we conducted a user study to determine the relationship between gestural motor space and display space. From the results of a user study, we define a user-driven mapping between an area on motor space and a point on visual space. For 16 points in display space, we find the motor space radius interval of a standard deviation from mean and angle interval that statistically cover 96% of trials.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/3DUI.2014.6798874&quot;&gt;http://dx.doi.org/10.1109/3DUI.2014.6798874&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/3dui/2014/posters&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;posters&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;21&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Wed, 22 Apr 2015 08:15:07 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">477 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Poster: Automatic Termination and Route Guide for 3D Scanning Based on Area Limitation</title>
    <link>http://vgtc.org/archives/3dui/2014/poster-automatic-termination-and-route-guide-3d-scanning-based-area-limitation</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Yuuki Ueba, Nobuchika Sakata, Shogo Nishida&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;In these days, 3D models are introduced as new digital contents such as data material for 3D printer. Accordingly, demand of 3D modeling for ordinary people has been increased. In case of using existed hand-held 3D scanning system, users have to estimate unmeasured spots to decide route for scanning and terminate scanning by watching a process of scanning iteratively. These many user operations impose burdens to users. In this paper, we propose a novel scanning system which provides route guidance by means of area limitation of scanning at the beginning.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/3DUI.2014.6798875&quot;&gt;http://dx.doi.org/10.1109/3DUI.2014.6798875&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/3dui/2014/posters&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;posters&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-keywords field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Keywords:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Interactive Scanning, Route N, Procams&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;22&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Wed, 22 Apr 2015 08:15:07 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">478 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Poster: Exploring 3D Volumetric Medical Data using Mobile Devices</title>
    <link>http://vgtc.org/archives/3dui/2014/poster-exploring-3d-volumetric-medical-data-using-mobile-devices</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Teddy Seyed, Francisco Marinho Rodrigues, Frank Maurer, Anthony Tang&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Medical imaging specialists have traditionally used keyboard and mouse based techniques and interfaces for examining both 2D and 3D medical images, but with newer imaging technologies resulting in significantly larger volumes of 3D medical images, these techniques that have become increasingly cumbersome for imaging specialists. To replace traditional techniques, using mobile devices present an effective means for navigating and exploring complex 3D medical data sets, as they provide increased fluidity and flexibility, leveraging people&#039;s existing skills with tangible objects.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/3DUI.2014.6798876&quot;&gt;http://dx.doi.org/10.1109/3DUI.2014.6798876&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/3dui/2014/posters&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;posters&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-keywords field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Keywords:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Mobile devices, medical imaging, isometric interactions, isotonic interactions, 3D navigation&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;23&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Wed, 22 Apr 2015 08:15:07 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">479 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Poster: Design and Development of a Virtual Reality System for Vocational Rehabilitation of Individuals with Disabilities</title>
    <link>http://vgtc.org/archives/3dui/2014/poster-design-and-development-virtual-reality-system-vocational-rehabilitation</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Evren Bozgeyikli, Lal Bozgeyikli, Matthew Clevenger, Andrew Raij, Redwan Alqasemi, Rajiv Dubey&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;This paper considers the design and development of a virtual reality system that aids in vocational rehabilitation of individuals with disabilities. The system focuses on three types of disabilities: autism spectrum disorder, traumatic brain injury, and severe mobility impairment. The system allows job trainers to rapidly assess the capabilities of individuals with disabilities, detect the most suitable job for them, and train them in a safe and motivating environment where there are no significant consequences of making errors.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/3DUI.2014.6798877&quot;&gt;http://dx.doi.org/10.1109/3DUI.2014.6798877&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/3dui/2014/posters&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;posters&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-keywords field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Keywords:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Virtual reality simulation, virtual interaction, tangible interaction, navigation through virtual environments, vocational rehabilitation, disabilities, gamification&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;24&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Wed, 22 Apr 2015 08:15:07 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">480 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Poster: Applying Tactile Languages for 3D Navigation</title>
    <link>http://vgtc.org/archives/3dui/2014/poster-applying-tactile-languages-3d-navigation</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Victor Adriel de J. Oliveira, Anderson Maciel&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;In this paper we present the design and evaluate alternative tactile vocabularies to support navigation in 3D environments. We have focused on the tactile communication expressiveness by applying a prefixation approach in the construction of the tactile icons. We conducted user experiments to analyze the effects of both prefixation and the use of tactile sequences on the user&amp;#039;s performance in a navigation task. Results show that the group that used the prefixation-based vocabulary performed better.&lt;/p&gt;
&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/3DUI.2014.6798878&quot;&gt;http://dx.doi.org/10.1109/3DUI.2014.6798878&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-video-download-url field-type-link-field field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Video:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://vimeo.com/groups/3dui2014/videos/90536743&quot;&gt;Download Video&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-running-time field-type-text field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Running Time:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;00:00:58&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/3dui/2014/posters&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;posters&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;25&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Wed, 22 Apr 2015 08:15:07 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">481 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Poster: A Comparative Study of Metaphors for Investigating Augmented Reality Artifacts</title>
    <link>http://vgtc.org/archives/3dui/2014/poster-comparative-study-metaphors-investigating-augmented-reality-artifacts</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Kimberly Zeitz, Rebecca Zeitz, Congwu Tao, Nicholas Polys&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Augmented Reality applications allow users to view real-world elements augmented by virtual content. Providing appropriate manipulation techniques for virtual objects has the potential to enhance user performance, decrease task completion time, and elicit a more positive user experience. With a goal of establishing guidelines to inform the selection of manipulation metaphors for the development of AR interfaces, we compared physical and touch manipulation metaphors for zoom and rotation techniques.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/3DUI.2014.6798879&quot;&gt;http://dx.doi.org/10.1109/3DUI.2014.6798879&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/3dui/2014/posters&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;posters&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;26&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Wed, 22 Apr 2015 08:15:07 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">482 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Poster: BrainTrek - An Immersive Environment for Investigating Neuronal Tissue</title>
    <link>http://vgtc.org/archives/3dui/2014/poster-braintrek-immersive-environment-investigating-neuronal-tissue</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Michael Morehead, Quinn Jones, Jared Blatt, Paul Holcomb, Juergen Schultz, Tom DeFanti, Mark Ellisman, Gianfranco Doretto, George A. Spirou&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;The high degree of complexity in cellular and circuit structure of the brain poses challenges for understanding tissue organization, extrapolated from large serial sections electron microscopy (ssEM) image data. We advocate the use of 3D immersive virtual reality (IVR) to facilitate the human analysis of such data. We have developed and evaluated the BrainTrek system - a CAVE-based IVR environment with a dedicated and intuitive user interface tailored to the investigation of neural tissue by scientists and educators.&lt;/p&gt;
&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/3DUI.2014.6798868&quot;&gt;http://dx.doi.org/10.1109/3DUI.2014.6798868&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-video-download-url field-type-link-field field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Video:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://vimeo.com/groups/3dui2014/videos/90535239&quot;&gt;Download Video&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-running-time field-type-text field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Running Time:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;00:01:01&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/3dui/2014/posters&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;posters&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;15&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Wed, 22 Apr 2015 08:10:09 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">471 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Poster: Kinect-based Automatic Scoring System for Spasmodic Torticollis</title>
    <link>http://vgtc.org/archives/3dui/2014/poster-kinect-based-automatic-scoring-system-spasmodic-torticollis</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Takuto Nakamura, Narihiro Nishimura, Takashi Asahi, Genko Oyama, Michi Sato, Hiroyuki Kajimoto&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Displacement and shaking of the human body are essential measures for the scoring of movement disorder. The aim of our research is to increase the accuracy and reproducibility of the scoring for spasmodic torticollis, a movement disorders that is characterized by poor head-posture. Although there are conventional scoring methods for torticollis severity, such as the Tsui Scale or TWSTRS, the results obtained are sometimes inaccurate or non-reproducible because these tests are performed manually.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/3DUI.2014.6798867&quot;&gt;http://dx.doi.org/10.1109/3DUI.2014.6798867&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-video-download-url field-type-link-field field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Video:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://vimeo.com/groups/3dui2014/videos/90535056&quot;&gt;Download Video&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-running-time field-type-text field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Running Time:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;00:01:00&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/3dui/2014/posters&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;posters&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-keywords field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Keywords:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Kinect, Spasmodic Torticollis, Automatic Scoring&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;14&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Wed, 22 Apr 2015 08:10:09 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">470 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Poster: Exploring the Integrality and Separability of the Leap Motion Controller for Direct Manipulation 3D Interaction</title>
    <link>http://vgtc.org/archives/3dui/2014/poster-exploring-integrality-and-separability-leap-motion-controller-direct</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Panagiotis Apostolellis, Brennon Bortz, Peng Mi, Nicholas Polys, Andy Hoegh&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;In this paper, we evaluate a new generation 5DOF tracker, the Leap Motion Controller, and the mouse for performing integral and separable 3D manipulation tasks in a stage lighting application. Based on the hypothesis that the Leap would outperform the mouse for the integral tasks of position and rotation while the mouse will prove better for the separable tasks of position and light intensity, as shown in a similar study by Jacob et al. [3], we designed an experiment to test this claim.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/3DUI.2014.6798866&quot;&gt;http://dx.doi.org/10.1109/3DUI.2014.6798866&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-video-download-url field-type-link-field field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Video:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://vimeo.com/groups/3dui2014/videos/90534925&quot;&gt;Download Video&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-running-time field-type-text field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Running Time:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;00:01:00&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/3dui/2014/posters&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;posters&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-keywords field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Keywords:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;3D Interaction, Leap Motion Controller, mouse, input devices, integrality and separability&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;13&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Wed, 22 Apr 2015 08:10:09 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">469 at http://vgtc.org</guid>
  </item>
  </channel>
</rss>
