<?xml version="1.0" encoding="utf-8" ?><rss version="2.0" xml:base="http://vgtc.org/taxonomy/term/556/all" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:foaf="http://xmlns.com/foaf/0.1/" xmlns:og="http://ogp.me/ns#" xmlns:rdfs="http://www.w3.org/2000/01/rdf-schema#" xmlns:sioc="http://rdfs.org/sioc/ns#" xmlns:sioct="http://rdfs.org/sioc/types#" xmlns:skos="http://www.w3.org/2004/02/skos/core#" xmlns:xsd="http://www.w3.org/2001/XMLSchema#">
  <channel>
    <title>Poster</title>
    <link>http://vgtc.org/taxonomy/term/556/all</link>
    <description></description>
    <language>en</language>
          <item>
    <title>The Effect of an Occluder on Near Field Depth Matching in Optical See-Through Augmented Reality</title>
    <link>http://vgtc.org/archives/vr/2014/effect-occluder-near-field-depth-matching-optical-see-through-augmented-reality</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Chunya Hua, Kenneth Moser, J. Edward Swan II&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;We have conducted an experiment to study the effect of an occluding surface on the accuracy of near field depth matching in augmented reality (AR). Our experiment was based on replicating a similar experiment conducted by Edwards et al. [2]. We used an AR haploscope [1], which allows us to independently manipulate accommodative demand and vergence angle of the visible image. Fifteen observers matched the perceived depth of an AR-presented virtual object with a physical pointer.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/VR.2014.6802095&quot;&gt;http://dx.doi.org/10.1109/VR.2014.6802095&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/vr/2014/poster&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;Poster&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;71&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Thu, 23 Apr 2015 03:58:59 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">1166 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Design and Evaluation of Binaural Auditory Rendering for CAVEs</title>
    <link>http://vgtc.org/archives/vr/2014/design-and-evaluation-binaural-auditory-rendering-caves</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Francesco Grani, Ferran Argelaguet, Valerie Gouranton, Marwan Badawi, Ronan Gaugne, Stefania Serafin, Anatole Lecuyer&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;We describe an experiment whose goal is to investigate the usage of different audio rendering techniques delivered through headphones while walking inside a wide four-side CAVE environment. In our experiment, participants had to physically walk along a virtual path exposed to different auditory stimuli. Each subject was exposed to three conditions: Stereo, Binaural sound spatially congruent with visual and binaural sound spatially incongruent with visuals and had to rate subjectively each.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/VR.2014.6802057&quot;&gt;http://dx.doi.org/10.1109/VR.2014.6802057&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/vr/2014/poster&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;Poster&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;35&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Thu, 23 Apr 2015 03:21:00 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">1162 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Audio-Visual Attractors for Capturing Attention to the Screens When Walking in CAVE Systems</title>
    <link>http://vgtc.org/archives/vr/2014/audio-visual-attractors-capturing-attention-screens-when-walking-cave-systems</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Francesco Grani, Ferran Argelaguet, Valerie Gouranton, Marwan Badawi, Ronan Gaugne, Stefania Serafin, Anatole Lecuyer&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;In four-sided CAVE systems, the absence of rear wall has been shown to decrease the level of immersion and can introduce breaks in presence. With this experiment we analyse how user attention is diverted while walking in VE when audio and/or visual attractors are present. Auditory feedback was delivered through binaural audio. The CAVE used for the experiment allowed users to walk up to 9m in straight line. \ Different ???attractors??ï¿½ were proposed (audio and/or visual, static or dynamic).&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/VR.2014.6802058&quot;&gt;http://dx.doi.org/10.1109/VR.2014.6802058&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/vr/2014/poster&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;Poster&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;36&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Thu, 23 Apr 2015 03:21:00 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">1163 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Virtual Speech Anxiety Training - Effects of Simulation Fidelity on User Experience</title>
    <link>http://vgtc.org/archives/vr/2014/virtual-speech-anxiety-training-effects-simulation-fidelity-user-experience</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Sandra Poeschl, Nicola Doering&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Realistic models in VR training applications are considered to positively influence presence and performance. The experimental study presented analyzed the effect of simulation fidelity (static vs. animated audience) on presence, perceived realism, and anxiety in a virtual speech anxiety training application. No influence on presence and perceived realism was shown, although an animated audience led to significantly higher effects in anxiety during giving a talk.&lt;/p&gt;
&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/VR.2014.6802073&quot;&gt;http://dx.doi.org/10.1109/VR.2014.6802073&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/vr/2014/poster&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;Poster&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;51&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Thu, 23 Apr 2015 03:13:12 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">1178 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Assessing Exertions: How an increased level of immersion unwittingly leads to more natural behavior</title>
    <link>http://vgtc.org/archives/vr/2014/assessing-exertions-how-increased-level-immersion-unwittingly-leads-more-natural</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Kevin Ponto, Karen Chen, Ross Tredinnick, Robert G. Radwin&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;This paper utilizes muscle exertions as a means to affect and study the behavior of participants in a virtual environment. Participants performed a simple lifting task both physically using an actual weight and virtually by monitoring surface EMG. While the participants subjectively indicated that their effort was the same for each of these presentation methods, we found significant differences in the muscle activity between the two virtual presentation methods.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/VR.2014.6802074&quot;&gt;http://dx.doi.org/10.1109/VR.2014.6802074&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/vr/2014/poster&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;Poster&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;52&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Thu, 23 Apr 2015 03:13:12 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">1179 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Design and Evaluation of Visual Feedback for Virtual Grasp</title>
    <link>http://vgtc.org/archives/vr/2014/design-and-evaluation-visual-feedback-virtual-grasp</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Mores Prachyabrued, Christoph W. Borst&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;We tuned and evaluated visual feedback techniques for virtual grasps. To date, development of such feedback has been largely ad-hoc, with minimal work that can guide technique selection. We considered several techniques including both standard and novel aspects. In terms of impact on real hand behavior, the best techniques all directly reveal penetrating hand configuration in some way. Subjectively, color changes are most liked.&lt;/p&gt;
&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/VR.2014.6802075&quot;&gt;http://dx.doi.org/10.1109/VR.2014.6802075&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/vr/2014/poster&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;Poster&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;53&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Thu, 23 Apr 2015 03:13:12 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">1180 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Social Presence in Mixed Agency Interactions</title>
    <link>http://vgtc.org/archives/vr/2014/social-presence-mixed-agency-interactions</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Andrew Robb, Benjamin Lok&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;In this paper, we present the preliminary results of an ongoing study exploring how mixed-agency teams influence feelings of social presence. Participants worked with a team composed of either two virtual humans or a team composed of one virtual human and one real human. We found that while the presence of a human teammate did not affect overall feelings of social presence, the presence of a human teammate did appear to strengthen participants&amp;#039; perceptions that their virtual teammates were not real.&lt;/p&gt;
&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/VR.2014.6802076&quot;&gt;http://dx.doi.org/10.1109/VR.2014.6802076&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/vr/2014/poster&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;Poster&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;54&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Thu, 23 Apr 2015 03:13:12 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">1181 at http://vgtc.org</guid>
  </item>
  <item>
    <title>An AR Edutainment System Supporting Bone Anatomy Learning</title>
    <link>http://vgtc.org/archives/vr/2014/ar-edutainment-system-supporting-bone-anatomy-learning</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Philipp Stefan, Patrick Wucherer, Yuji Oyamada, Meng Ma, Alexander Schoch, Motoko Kanegae, Naoki Shimizu, Tatsuya Kodera, Sebastien Callier, Matthias Weigl, Maki Sugimoto, Pascal Fallavollita, Hideo Saito, Nassir Navab&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;We present a medical Augmented Reality (AR) edutainment system for bone anatomy learning. This learning environment, called AR bone puzzle, is a metaphor for bone anatomy learning with AR visualization and intuitive interaction. AR bone puzzle uses its user&amp;#039;s body as a puzzle frame and computer generated virtual bones as puzzle pieces. Users learn bone anatomy by assembling the virtual bone pieces on their body. Key features of this system are 3D AR visualization and intuitive gesture based user interaction.&lt;/p&gt;
&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/VR.2014.6802077&quot;&gt;http://dx.doi.org/10.1109/VR.2014.6802077&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/vr/2014/poster&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;Poster&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;55&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Thu, 23 Apr 2015 03:13:12 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">1182 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Comparative Study of Input Devices for a VR Mine Simulation</title>
    <link>http://vgtc.org/archives/vr/2014/comparative-study-input-devices-vr-mine-simulation</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;David Zielinski, Brendan Macdonald, Regis Kopper&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;The National Institute for Occupational Safety and Health (NIOSH) has a virtual reality (VR) laboratory for training mine workers in critical situations. Input devices at the laboratory are an Xbox 360 game pad and an air mouse. We wanted to test if there was a benefit from upgrading to a 6-DOF tracking system. Thus, we conducted a pilot study for three tasks (selection, navigation, and maneuvering) and three devices (gamepad, air mouse, 6-DOF wand). Results indicate that the wand allows users to complete tasks faster and is preferred by users.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/VR.2014.6802083&quot;&gt;http://dx.doi.org/10.1109/VR.2014.6802083&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/vr/2014/poster&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;Poster&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;61&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Thu, 23 Apr 2015 03:13:12 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">1188 at http://vgtc.org</guid>
  </item>
  <item>
    <title>MuVR: A Multi-user Virtual Reality Platform</title>
    <link>http://vgtc.org/archives/vr/2014/muvr-multi-user-virtual-reality-platform</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Jerald Thomas, Raghav Bashyal, Samantha Goldstein, Evan Suma&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Consumer adoption of virtual reality technology has historically been \ held back by poor accessibility, the lack of intuitive multi- user \ capabilities, dependence on external infrastructure for render- ing \ and tracking, and the effort required to enter virtual reality \ systems. This poster presents the current status of MuVR, a Multi-User \ Virtual Reality platform that seeks to overcome these hindrances.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/VR.2014.6802078&quot;&gt;http://dx.doi.org/10.1109/VR.2014.6802078&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/vr/2014/poster&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;Poster&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;56&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Thu, 23 Apr 2015 03:13:12 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">1183 at http://vgtc.org</guid>
  </item>
  <item>
    <title>CAVE Visualization of the IceCube Neutrino Detector</title>
    <link>http://vgtc.org/archives/vr/2014/cave-visualization-icecube-neutrino-detector</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Ross Tredinnick, James Vanderheiden, Clayton Suplinski, James Madsen&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Neutrinos are nearly massless, weakly interacting particles that provide opportunities to better understand the basic building blocks of matter. IceCube, located at the South Pole, is the largest operating neutrino detector in the world. This paper presents a VR application for visualization of IceCube&#039;s data within a C6 CAVE system. The visualization of data in a true scale recreation of the detection system allows viewing of events from arbitrary locations both forward and backward in time.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/VR.2014.6802079&quot;&gt;http://dx.doi.org/10.1109/VR.2014.6802079&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/vr/2014/poster&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;Poster&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;57&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Thu, 23 Apr 2015 03:13:12 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">1184 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Responsive Audiences - Nonverbal Cues as Reactions to a Speaker&#039;s Behavior</title>
    <link>http://vgtc.org/archives/vr/2014/responsive-audiences-nonverbal-cues-reactions-speakers-behavior</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Ana-Despina Tudor, Ilinca Mustatea, Sandra Poeschl, Nicola Doering&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Presentation skills that involve public speaking are an important asset in one???s careers or during one???s study. One way to learn such skills is to use virtual audiences (VA) that simulate the reactions of a live public. A study was conducted to conceptualize the design of such a VA. It was inquired how the nonverbal cues of live audiences vary depending on a speaker???s gaze patterns and vocal loudness. 36 students (listeners) were videotaped during a public speaking situation.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/VR.2014.6802080&quot;&gt;http://dx.doi.org/10.1109/VR.2014.6802080&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/vr/2014/poster&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;Poster&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;58&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Thu, 23 Apr 2015 03:13:12 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">1185 at http://vgtc.org</guid>
  </item>
  <item>
    <title>VR Central Venous Access Simulation System for Newborns</title>
    <link>http://vgtc.org/archives/vr/2014/vr-central-venous-access-simulation-system-newborns</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Lizeth Vega-Medina, Byron Perez-Gutierrez, Gerardo Tibamoso, Alvaro Uribe-Quevedo, Norman Jaimes&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Central venous access is an invasive medical procedure of high complexity used in critically ill patients. Its implementation requires great skills and knowledge from a health care specialist. Advances in patient simulators present solutions regarding children and adults, however, newborn simulators are scarce. \  \ This paper presents the development of a newborn&#039;s central venous access simulator for training and educational purposes.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/VR.2014.6802081&quot;&gt;http://dx.doi.org/10.1109/VR.2014.6802081&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/vr/2014/poster&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;Poster&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;59&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Thu, 23 Apr 2015 03:13:12 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">1186 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Modeling Interactions in Continuum Traffic</title>
    <link>http://vgtc.org/archives/vr/2014/modeling-interactions-continuum-traffic</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Hua Wang, Tianlu Mao, Zhaoqi Wang&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;It is a big challenge to generate the traffic scenarios with frequent lane changes in continuum traffic simulations. In this paper, we present a novel macroscopic method, named interactable cooperative driving lattice hydrodynamic model (Interactable CDLH model). We describe traffic flow along lanes and flow interactions between lanes in a uniformly continuum frame. We further consider various constraints for a detailed lane-changing simulation. The model owns the efficiency of traditional macroscopic traffic models and can describe lane-changing behaviors effectively.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/VR.2014.6802082&quot;&gt;http://dx.doi.org/10.1109/VR.2014.6802082&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/vr/2014/poster&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;Poster&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;60&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Thu, 23 Apr 2015 03:13:12 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">1187 at http://vgtc.org</guid>
  </item>
  <item>
    <title>Reflectance and Light Source Estimation for Indoor AR Applications</title>
    <link>http://vgtc.org/archives/vr/2014/reflectance-and-light-source-estimation-indoor-ar-applications</link>
    <description>&lt;div class=&quot;field field-name-field-authors field-type-text field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Authors:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;Alexander Plopski, Tomohiro Mashita, Kiyoshi Kiyokawa, Haruo Takemura&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;We present an approach for real-time augmentation of an environment composed of materials with different texture and reflectance properties without the need of application-specific hardware or extensive preparation. Our solution uses a set of RGB images of a reconstructed model to optimize the reflectance parameters and light locations. The environment is stored in a voxel grid and we optimize the reflectance properties and colour of each voxel through inverse rendering.&lt;/p&gt;&lt;div class=&quot;field field-name-field-doi-bookmark field-type-link-field field-label-inline clearfix&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;DOI Bookmark:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/VR.2014.6802072&quot;&gt;http://dx.doi.org/10.1109/VR.2014.6802072&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-taxonomy-vocabulary-4 field-type-taxonomy-term-reference field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Archives:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;&lt;a href=&quot;/archives/vr/2014/poster&quot; typeof=&quot;skos:Concept&quot; property=&quot;rdfs:label skos:prefLabel&quot; datatype=&quot;&quot;&gt;Poster&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;field field-name-field-weight field-type-number-integer field-label-above&quot;&gt;&lt;div class=&quot;field-label&quot;&gt;Weight:&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot;&gt;50&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
     <pubDate>Thu, 23 Apr 2015 03:13:09 +0000</pubDate>
 <dc:creator>admin</dc:creator>
 <guid isPermaLink="false">1177 at http://vgtc.org</guid>
  </item>
  </channel>
</rss>
