---
title: A Gaze-enabled Graph Visualization to Improve Graph Reading Tasks
layout: default
permalink: /archives/eurovis/2014/gaze-enabled-graph-visualization-improve-graph-reading-tasks
breadcrumb:
  - ['Home', '/']
  - ['conference archives', '/archives']
  - ['EuroVis', '/archives/eurovis']
  - ['2014', '/archives/eurovis/2014']
  - ['papers', '/archives/eurovis/2014/papers']
---


  

      <span property="dc:title" content="A Gaze-enabled Graph Visualization to Improve Graph Reading Tasks" class="rdf-meta element-hidden"></span>

  

  <div class="content">

    <div class="field field-name-field-authors field-type-text field-label-above"><div class="field-label">Authors:&nbsp;</div><div class="field-items"><div class="field-item even">Mershack Okoe, Sayeed Safayet Alam, and Radu Jianu </div></div></div><div class="field field-name-field-doi-bookmark field-type-link-field field-label-above"><div class="field-label">DOI Bookmark:&nbsp;</div><div class="field-items"><div class="field-item even"><a href="http://dx.doi.org/10.1111/cgf.12381">http://dx.doi.org/10.1111/cgf.12381</a></div></div></div><div class="field field-name-field-keywords field-type-text field-label-above"><div class="field-label">Keywords:&nbsp;</div><div class="field-items"><div class="field-item even">Eye tracking, gaze contingent graph visualization</div></div></div><div class="field-label">Abstract:&nbsp;</div>Performing typical network tasks such as node scanning and path tracing can be difficult in large and dense graphs. To alleviate this problem we use eye-tracking as an interactive input to detect tasks that users intend to perform and then produce unobtrusive visual changes that support these tasks. First, we introduce a novel fovea based filtering that dims out edges with endpoints far removed from a user's view focus. Second, we highlight edges that are being traced at any given moment or have been the focus of recent attention. Third, we track recently viewed nodes and increase the saliency of their neighborhoods. All visual responses are unobtrusive and easily ignored to avoid unintentional distraction and to account for the imprecise and low-resolution nature of eyetracking. We also introduce a novel gaze-correction approach that relies on knowledge about the network layout to reduce eye-tracking error. Finally, we present results from a controlled user study showing that our methods led to a statistically significant accuracy improvement in one of two network tasks and that our gaze-correction algorithm enables more accurate eye-tracking interaction.<div class="field field-name-field-running-time field-type-text field-label-above"><div class="field-label">Running Time:&nbsp;</div><div class="field-items"><div class="field-item even">00:25:39</div></div></div><div class="field field-name-field-vimeo field-type-video-embed-field field-label-above"><div class="field-label">Conference presentation:&nbsp;</div><div class="field-items"><div class="field-item even">

<div class="embedded-video">

  <div class="player">

    <iframe id="vimeo-100166449" width="640" height="360" src="//player.vimeo.com/video/100166449?width=640&amp;height=360&amp;color=00adef&amp;portrait=1&amp;title=1&amp;byline=1&amp;autoplay=0&amp;loop=0&amp;player_id=vimeo-100166449" frameborder="0" webkitAllowFullScreen mozallowfullscreen allowfullscreen></iframe>  </div>

</div>

</div></div></div><div id="disqus_thread"><noscript><p><a href="http://vgtc.disqus.com/?url=http%3A%2F%2Fvgtc.org%2Farchives%2Feurovis%2F2014%2Fgaze-enabled-graph-visualization-improve-graph-reading-tasks">View the discussion thread.</a></p></noscript></div>  </div>

