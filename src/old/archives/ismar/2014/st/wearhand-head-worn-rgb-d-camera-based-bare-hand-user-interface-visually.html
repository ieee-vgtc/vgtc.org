---
title: "WeARHand: Head-Worn, RGB-D Camera-Based, Bare-Hand User Interface with Visually Enhanced Depth Perception"
layout: default
permalink: /archives/ismar/2014/st/wearhand-head-worn-rgb-d-camera-based-bare-hand-user-interface-visually
breadcrumb:
  - ['Home', '/']
  - ['conference archives', '/archives']
  - ['ISMAR', '/archives/ismar']
  - ['2014', '/archives/ismar/2014']
  - ['S&amp;T Papers', '/archives/ismar/2014/st/papers']
---


  

      <span property="dc:title" content="WeARHand: Head-Worn, RGB-D Camera-Based, Bare-Hand User Interface with Visually Enhanced Depth Perception" class="rdf-meta element-hidden"></span>

  

  <div class="content">

    <div class="field field-name-field-authors field-type-text field-label-above"><div class="field-label">Authors:&nbsp;</div><div class="field-items"><div class="field-item even">Taejin Ha, Steven Feiner, Woontack Woo</div></div></div><div class="field field-name-field-doi-bookmark field-type-link-field field-label-above"><div class="field-label">DOI Bookmark:&nbsp;</div><div class="field-items"><div class="field-item even"><a href="http://dx.doi.org/10.1109/ismar.2014.6948431">http://dx.doi.org/10.1109/ismar.2014.6948431</a></div></div></div><div class="field field-name-field-keywords field-type-text field-label-above"><div class="field-label">Keywords:&nbsp;</div><div class="field-items"><div class="field-item even">3D User Interfaces, Augmented Reality, Hand Interaction, Virtual 3D Object Manipulation, Wearable Computing</div></div></div><div class="field-label">Abstract:&nbsp;</div>We introduce WeARHand, which allows a user to manipulate virtual 3D objects with a bare hand in a wearable augmented reality (AR) environment. Our method uses no environmentally tethered tracking devices and localizes a pair of near-range and far-range RGB-D cameras mounted on a head-worn display and a moving bare hand in 3D space by exploiting depth input data. Depth perception is enhanced through egocentric visual feedback, including a semi-transparent proxy hand. We implement a virtual hand interaction technique and feedback approaches, and evaluate their performance and usability. The proposed method can apply to many 3D interaction scenarios using hands in a wearable AR environment, such as AR information browsing, maintenance, design, and games.<div id="disqus_thread"><noscript><p><a href="http://vgtc.disqus.com/?url=http%3A%2F%2Fvgtc.org%2Farchives%2Fismar%2F2014%2Fst%2Fwearhand-head-worn-rgb-d-camera-based-bare-hand-user-interface-visually">View the discussion thread.</a></p></noscript></div>  </div>

