---
title: Using Relative Head and Hand-Target Features to Predict Intention in 3D Moving-Target Selection
layout: default
permalink: /archives/vr/2014/using-relative-head-and-hand-target-features-predict-intention-3d-moving-target
breadcrumb:
  - ['Home', '/']
  - ['conference archives', '/archives']
  - ['VR', '/archives/vr']
  - ['2014', '/archives/vr/2014']
  - ['Short Paper', '/archives/vr/2014/short-paper']
---


  

      <span property="dc:title" content="Using Relative Head and Hand-Target Features to Predict Intention in 3D Moving-Target Selection" class="rdf-meta element-hidden"></span>

  

  <div class="content">

    <div class="field field-name-field-authors field-type-text field-label-above"><div class="field-label">Authors:&nbsp;</div><div class="field-items"><div class="field-item even">Juan Sebastian Casallas, James H. Oliver, Jonathan W. Kelly, Frederic Merienne, Samir Garbaya</div></div></div><div class="field field-name-field-doi-bookmark field-type-link-field field-label-above"><div class="field-label">DOI Bookmark:&nbsp;</div><div class="field-items"><div class="field-item even"><a href="http://dx.doi.org/10.1109/VR.2014.6802050">http://dx.doi.org/10.1109/VR.2014.6802050</a></div></div></div><div class="field-label">Abstract:&nbsp;</div>Selection of moving targets is a common, yet complex task in human-computer interaction and virtual reality. Predicting user intention may be beneficial to address the challenges inherent in interaction techniques for moving-target selection. This article extends previous models by integrating relative head-target and hand-target features to predict intended moving targets. The features are calculated in a time window ending at roughly two-thirds of the total target selection time and evaluated using decision trees. With two targets, this model predicts choice with up to ~72% accuracy on general moving-target selection tasks and up to ~78% by also including task-related target properties.<div class="field field-name-field-running-time field-type-text field-label-above"><div class="field-label">Running Time:&nbsp;</div><div class="field-items"><div class="field-item even">00:14:55</div></div></div><div class="field field-name-field-vimeo field-type-video-embed-field field-label-above"><div class="field-label">Conference presentation:&nbsp;</div><div class="field-items"><div class="field-item even">

<div class="embedded-video">

  <div class="player">

    <iframe id="vimeo-91745974" width="640" height="360" src="//player.vimeo.com/video/91745974?width=640&amp;height=360&amp;color=00adef&amp;portrait=1&amp;title=1&amp;byline=1&amp;autoplay=0&amp;loop=0&amp;player_id=vimeo-91745974" frameborder="0" webkitAllowFullScreen mozallowfullscreen allowfullscreen></iframe>  </div>

</div>

</div></div></div><div id="disqus_thread"><noscript><p><a href="http://vgtc.disqus.com/?url=http%3A%2F%2Fvgtc.org%2Farchives%2Fvr%2F2014%2Fusing-relative-head-and-hand-target-features-predict-intention-3d-moving-target">View the discussion thread.</a></p></noscript></div>  </div>

