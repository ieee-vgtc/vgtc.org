---
title: Real-time Human Pose and Shape Estimation for Virtual Try-On Using a Single Commodity Depth Camera
layout: default
permalink: /archives/vr/2014/real-time-human-pose-and-shape-estimation-virtual-try-using-single-commodity-depth
breadcrumb:
  - ['Home', '/']
  - ['conference archives', '/archives']
  - ['VR', '/archives/vr']
  - ['2014', '/archives/vr/2014']
  - ['Long Paper', '/archives/vr/2014/long-paper']
---


  

      <span property="dc:title" content="Real-time Human Pose and Shape Estimation for Virtual Try-On Using a Single Commodity Depth Camera" class="rdf-meta element-hidden"></span>

  

  <div class="content">

    <div class="field field-name-field-authors field-type-text field-label-above"><div class="field-label">Authors:&nbsp;</div><div class="field-items"><div class="field-item even">Mao Ye, Huamin Wang, Nianchen Deng, Xubo Yang, Ruigang Yang</div></div></div><div class="field-label">Abstract:&nbsp;</div>We present a system that allows the user to virtually try on new clothes. It uses a single commodity depth camera to capture the user in 3D. Both the pose and the shape of the user are estimated with a novel real-time template-based approach that performs tracking and shape adaptation jointly. The result is then used to drive realistic cloth simulation, in which the synthesized clothes are overlayed on the input image. The main challenge is to handle missing data and pose ambiguities due to the monocular setup, which captures less than 50 percent of the full body. Our solution is to incorporate automatic shape adaptation and novel constraints in pose tracking. The effectiveness of our system is demonstrated with a number of examples.<div id="disqus_thread"><noscript><p><a href="http://vgtc.disqus.com/?url=http%3A%2F%2Fvgtc.org%2Farchives%2Fvr%2F2014%2Freal-time-human-pose-and-shape-estimation-virtual-try-using-single-commodity-depth">View the discussion thread.</a></p></noscript></div>  </div>

